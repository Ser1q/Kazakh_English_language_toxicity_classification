{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.716527709661599,
  "eval_steps": 500,
  "global_step": 3500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04904364884747425,
      "grad_norm": 11.129484176635742,
      "learning_rate": 4.9514467876410006e-05,
      "loss": 0.1417,
      "step": 100
    },
    {
      "epoch": 0.0980872976949485,
      "grad_norm": 0.05864883214235306,
      "learning_rate": 4.9024031387935264e-05,
      "loss": 0.0971,
      "step": 200
    },
    {
      "epoch": 0.14713094654242276,
      "grad_norm": 0.03857949376106262,
      "learning_rate": 4.853359489946052e-05,
      "loss": 0.0801,
      "step": 300
    },
    {
      "epoch": 0.196174595389897,
      "grad_norm": 0.017243042588233948,
      "learning_rate": 4.804315841098578e-05,
      "loss": 0.1,
      "step": 400
    },
    {
      "epoch": 0.24521824423737126,
      "grad_norm": 0.12854889035224915,
      "learning_rate": 4.755272192251104e-05,
      "loss": 0.0972,
      "step": 500
    },
    {
      "epoch": 0.2942618930848455,
      "grad_norm": 0.5904366374015808,
      "learning_rate": 4.7062285434036295e-05,
      "loss": 0.2458,
      "step": 600
    },
    {
      "epoch": 0.34330554193231977,
      "grad_norm": 2.2150566577911377,
      "learning_rate": 4.657184894556155e-05,
      "loss": 0.2226,
      "step": 700
    },
    {
      "epoch": 0.392349190779794,
      "grad_norm": 4.080173492431641,
      "learning_rate": 4.608141245708681e-05,
      "loss": 0.2124,
      "step": 800
    },
    {
      "epoch": 0.4413928396272683,
      "grad_norm": 2.6016056537628174,
      "learning_rate": 4.559097596861207e-05,
      "loss": 0.2098,
      "step": 900
    },
    {
      "epoch": 0.4904364884747425,
      "grad_norm": 3.0120298862457275,
      "learning_rate": 4.5100539480137326e-05,
      "loss": 0.23,
      "step": 1000
    },
    {
      "epoch": 0.5394801373222168,
      "grad_norm": 8.036979675292969,
      "learning_rate": 4.4610102991662583e-05,
      "loss": 0.2088,
      "step": 1100
    },
    {
      "epoch": 0.588523786169691,
      "grad_norm": 7.919243335723877,
      "learning_rate": 4.411966650318784e-05,
      "loss": 0.2009,
      "step": 1200
    },
    {
      "epoch": 0.6375674350171653,
      "grad_norm": 4.389970302581787,
      "learning_rate": 4.36292300147131e-05,
      "loss": 0.1827,
      "step": 1300
    },
    {
      "epoch": 0.6866110838646395,
      "grad_norm": 5.468738555908203,
      "learning_rate": 4.313879352623835e-05,
      "loss": 0.2143,
      "step": 1400
    },
    {
      "epoch": 0.7356547327121138,
      "grad_norm": 5.206825256347656,
      "learning_rate": 4.2648357037763614e-05,
      "loss": 0.214,
      "step": 1500
    },
    {
      "epoch": 0.784698381559588,
      "grad_norm": 1.1600117683410645,
      "learning_rate": 4.215792054928887e-05,
      "loss": 0.2159,
      "step": 1600
    },
    {
      "epoch": 0.8337420304070623,
      "grad_norm": 1.6035795211791992,
      "learning_rate": 4.166748406081413e-05,
      "loss": 0.2043,
      "step": 1700
    },
    {
      "epoch": 0.8827856792545365,
      "grad_norm": 6.164929389953613,
      "learning_rate": 4.117704757233938e-05,
      "loss": 0.2055,
      "step": 1800
    },
    {
      "epoch": 0.9318293281020108,
      "grad_norm": 8.087772369384766,
      "learning_rate": 4.068661108386464e-05,
      "loss": 0.1858,
      "step": 1900
    },
    {
      "epoch": 0.980872976949485,
      "grad_norm": 1.5454144477844238,
      "learning_rate": 4.01961745953899e-05,
      "loss": 0.1859,
      "step": 2000
    },
    {
      "epoch": 1.0299166257969592,
      "grad_norm": 1.666582703590393,
      "learning_rate": 3.970573810691516e-05,
      "loss": 0.1327,
      "step": 2100
    },
    {
      "epoch": 1.0789602746444336,
      "grad_norm": 12.013948440551758,
      "learning_rate": 3.921530161844041e-05,
      "loss": 0.107,
      "step": 2200
    },
    {
      "epoch": 1.128003923491908,
      "grad_norm": 0.38277551531791687,
      "learning_rate": 3.872486512996567e-05,
      "loss": 0.119,
      "step": 2300
    },
    {
      "epoch": 1.177047572339382,
      "grad_norm": 0.8005583882331848,
      "learning_rate": 3.823442864149093e-05,
      "loss": 0.1106,
      "step": 2400
    },
    {
      "epoch": 1.2260912211868562,
      "grad_norm": 0.04874178394675255,
      "learning_rate": 3.774399215301619e-05,
      "loss": 0.1059,
      "step": 2500
    },
    {
      "epoch": 1.2751348700343306,
      "grad_norm": 3.550358772277832,
      "learning_rate": 3.725355566454144e-05,
      "loss": 0.1446,
      "step": 2600
    },
    {
      "epoch": 1.324178518881805,
      "grad_norm": 7.042727470397949,
      "learning_rate": 3.67631191760667e-05,
      "loss": 0.1197,
      "step": 2700
    },
    {
      "epoch": 1.373222167729279,
      "grad_norm": 1.7681925296783447,
      "learning_rate": 3.627268268759196e-05,
      "loss": 0.1254,
      "step": 2800
    },
    {
      "epoch": 1.4222658165767532,
      "grad_norm": 15.625740051269531,
      "learning_rate": 3.5782246199117216e-05,
      "loss": 0.1304,
      "step": 2900
    },
    {
      "epoch": 1.4713094654242276,
      "grad_norm": 0.682011067867279,
      "learning_rate": 3.529180971064247e-05,
      "loss": 0.1152,
      "step": 3000
    },
    {
      "epoch": 1.520353114271702,
      "grad_norm": 0.8218663334846497,
      "learning_rate": 3.480137322216773e-05,
      "loss": 0.123,
      "step": 3100
    },
    {
      "epoch": 1.569396763119176,
      "grad_norm": 20.564716339111328,
      "learning_rate": 3.431093673369299e-05,
      "loss": 0.1279,
      "step": 3200
    },
    {
      "epoch": 1.6184404119666502,
      "grad_norm": 1.2603421211242676,
      "learning_rate": 3.3820500245218246e-05,
      "loss": 0.0992,
      "step": 3300
    },
    {
      "epoch": 1.6674840608141246,
      "grad_norm": 2.3616936206817627,
      "learning_rate": 3.3330063756743504e-05,
      "loss": 0.1098,
      "step": 3400
    },
    {
      "epoch": 1.716527709661599,
      "grad_norm": 0.171383798122406,
      "learning_rate": 3.283962726826876e-05,
      "loss": 0.1333,
      "step": 3500
    }
  ],
  "logging_steps": 100,
  "max_steps": 10195,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.473106176749568e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
