{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 4.168710152035311,
  "eval_steps": 500,
  "global_step": 8500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04904364884747425,
      "grad_norm": 11.129484176635742,
      "learning_rate": 4.9514467876410006e-05,
      "loss": 0.1417,
      "step": 100
    },
    {
      "epoch": 0.0980872976949485,
      "grad_norm": 0.05864883214235306,
      "learning_rate": 4.9024031387935264e-05,
      "loss": 0.0971,
      "step": 200
    },
    {
      "epoch": 0.14713094654242276,
      "grad_norm": 0.03857949376106262,
      "learning_rate": 4.853359489946052e-05,
      "loss": 0.0801,
      "step": 300
    },
    {
      "epoch": 0.196174595389897,
      "grad_norm": 0.017243042588233948,
      "learning_rate": 4.804315841098578e-05,
      "loss": 0.1,
      "step": 400
    },
    {
      "epoch": 0.24521824423737126,
      "grad_norm": 0.12854889035224915,
      "learning_rate": 4.755272192251104e-05,
      "loss": 0.0972,
      "step": 500
    },
    {
      "epoch": 0.2942618930848455,
      "grad_norm": 0.5904366374015808,
      "learning_rate": 4.7062285434036295e-05,
      "loss": 0.2458,
      "step": 600
    },
    {
      "epoch": 0.34330554193231977,
      "grad_norm": 2.2150566577911377,
      "learning_rate": 4.657184894556155e-05,
      "loss": 0.2226,
      "step": 700
    },
    {
      "epoch": 0.392349190779794,
      "grad_norm": 4.080173492431641,
      "learning_rate": 4.608141245708681e-05,
      "loss": 0.2124,
      "step": 800
    },
    {
      "epoch": 0.4413928396272683,
      "grad_norm": 2.6016056537628174,
      "learning_rate": 4.559097596861207e-05,
      "loss": 0.2098,
      "step": 900
    },
    {
      "epoch": 0.4904364884747425,
      "grad_norm": 3.0120298862457275,
      "learning_rate": 4.5100539480137326e-05,
      "loss": 0.23,
      "step": 1000
    },
    {
      "epoch": 0.5394801373222168,
      "grad_norm": 8.036979675292969,
      "learning_rate": 4.4610102991662583e-05,
      "loss": 0.2088,
      "step": 1100
    },
    {
      "epoch": 0.588523786169691,
      "grad_norm": 7.919243335723877,
      "learning_rate": 4.411966650318784e-05,
      "loss": 0.2009,
      "step": 1200
    },
    {
      "epoch": 0.6375674350171653,
      "grad_norm": 4.389970302581787,
      "learning_rate": 4.36292300147131e-05,
      "loss": 0.1827,
      "step": 1300
    },
    {
      "epoch": 0.6866110838646395,
      "grad_norm": 5.468738555908203,
      "learning_rate": 4.313879352623835e-05,
      "loss": 0.2143,
      "step": 1400
    },
    {
      "epoch": 0.7356547327121138,
      "grad_norm": 5.206825256347656,
      "learning_rate": 4.2648357037763614e-05,
      "loss": 0.214,
      "step": 1500
    },
    {
      "epoch": 0.784698381559588,
      "grad_norm": 1.1600117683410645,
      "learning_rate": 4.215792054928887e-05,
      "loss": 0.2159,
      "step": 1600
    },
    {
      "epoch": 0.8337420304070623,
      "grad_norm": 1.6035795211791992,
      "learning_rate": 4.166748406081413e-05,
      "loss": 0.2043,
      "step": 1700
    },
    {
      "epoch": 0.8827856792545365,
      "grad_norm": 6.164929389953613,
      "learning_rate": 4.117704757233938e-05,
      "loss": 0.2055,
      "step": 1800
    },
    {
      "epoch": 0.9318293281020108,
      "grad_norm": 8.087772369384766,
      "learning_rate": 4.068661108386464e-05,
      "loss": 0.1858,
      "step": 1900
    },
    {
      "epoch": 0.980872976949485,
      "grad_norm": 1.5454144477844238,
      "learning_rate": 4.01961745953899e-05,
      "loss": 0.1859,
      "step": 2000
    },
    {
      "epoch": 1.0299166257969592,
      "grad_norm": 1.666582703590393,
      "learning_rate": 3.970573810691516e-05,
      "loss": 0.1327,
      "step": 2100
    },
    {
      "epoch": 1.0789602746444336,
      "grad_norm": 12.013948440551758,
      "learning_rate": 3.921530161844041e-05,
      "loss": 0.107,
      "step": 2200
    },
    {
      "epoch": 1.128003923491908,
      "grad_norm": 0.38277551531791687,
      "learning_rate": 3.872486512996567e-05,
      "loss": 0.119,
      "step": 2300
    },
    {
      "epoch": 1.177047572339382,
      "grad_norm": 0.8005583882331848,
      "learning_rate": 3.823442864149093e-05,
      "loss": 0.1106,
      "step": 2400
    },
    {
      "epoch": 1.2260912211868562,
      "grad_norm": 0.04874178394675255,
      "learning_rate": 3.774399215301619e-05,
      "loss": 0.1059,
      "step": 2500
    },
    {
      "epoch": 1.2751348700343306,
      "grad_norm": 3.550358772277832,
      "learning_rate": 3.725355566454144e-05,
      "loss": 0.1446,
      "step": 2600
    },
    {
      "epoch": 1.324178518881805,
      "grad_norm": 7.042727470397949,
      "learning_rate": 3.67631191760667e-05,
      "loss": 0.1197,
      "step": 2700
    },
    {
      "epoch": 1.373222167729279,
      "grad_norm": 1.7681925296783447,
      "learning_rate": 3.627268268759196e-05,
      "loss": 0.1254,
      "step": 2800
    },
    {
      "epoch": 1.4222658165767532,
      "grad_norm": 15.625740051269531,
      "learning_rate": 3.5782246199117216e-05,
      "loss": 0.1304,
      "step": 2900
    },
    {
      "epoch": 1.4713094654242276,
      "grad_norm": 0.682011067867279,
      "learning_rate": 3.529180971064247e-05,
      "loss": 0.1152,
      "step": 3000
    },
    {
      "epoch": 1.520353114271702,
      "grad_norm": 0.8218663334846497,
      "learning_rate": 3.480137322216773e-05,
      "loss": 0.123,
      "step": 3100
    },
    {
      "epoch": 1.569396763119176,
      "grad_norm": 20.564716339111328,
      "learning_rate": 3.431093673369299e-05,
      "loss": 0.1279,
      "step": 3200
    },
    {
      "epoch": 1.6184404119666502,
      "grad_norm": 1.2603421211242676,
      "learning_rate": 3.3820500245218246e-05,
      "loss": 0.0992,
      "step": 3300
    },
    {
      "epoch": 1.6674840608141246,
      "grad_norm": 2.3616936206817627,
      "learning_rate": 3.3330063756743504e-05,
      "loss": 0.1098,
      "step": 3400
    },
    {
      "epoch": 1.716527709661599,
      "grad_norm": 0.171383798122406,
      "learning_rate": 3.283962726826876e-05,
      "loss": 0.1333,
      "step": 3500
    },
    {
      "epoch": 1.765571358509073,
      "grad_norm": 0.1327095478773117,
      "learning_rate": 3.234919077979402e-05,
      "loss": 0.1209,
      "step": 3600
    },
    {
      "epoch": 1.8146150073565472,
      "grad_norm": 1.1744441986083984,
      "learning_rate": 3.185875429131928e-05,
      "loss": 0.1126,
      "step": 3700
    },
    {
      "epoch": 1.8636586562040216,
      "grad_norm": 15.105277061462402,
      "learning_rate": 3.1368317802844535e-05,
      "loss": 0.1319,
      "step": 3800
    },
    {
      "epoch": 1.912702305051496,
      "grad_norm": 7.916051387786865,
      "learning_rate": 3.0877881314369786e-05,
      "loss": 0.1296,
      "step": 3900
    },
    {
      "epoch": 1.96174595389897,
      "grad_norm": 0.3864770829677582,
      "learning_rate": 3.038744482589505e-05,
      "loss": 0.1327,
      "step": 4000
    },
    {
      "epoch": 2.0107896027464442,
      "grad_norm": 27.881778717041016,
      "learning_rate": 2.9897008337420308e-05,
      "loss": 0.0878,
      "step": 4100
    },
    {
      "epoch": 2.0598332515939184,
      "grad_norm": 0.6641351580619812,
      "learning_rate": 2.9406571848945563e-05,
      "loss": 0.0604,
      "step": 4200
    },
    {
      "epoch": 2.108876900441393,
      "grad_norm": 0.08584930002689362,
      "learning_rate": 2.891613536047082e-05,
      "loss": 0.0637,
      "step": 4300
    },
    {
      "epoch": 2.157920549288867,
      "grad_norm": 17.782451629638672,
      "learning_rate": 2.8425698871996075e-05,
      "loss": 0.0453,
      "step": 4400
    },
    {
      "epoch": 2.2069641981363413,
      "grad_norm": 0.03465844690799713,
      "learning_rate": 2.793526238352134e-05,
      "loss": 0.0639,
      "step": 4500
    },
    {
      "epoch": 2.256007846983816,
      "grad_norm": 0.05975571274757385,
      "learning_rate": 2.7444825895046593e-05,
      "loss": 0.0631,
      "step": 4600
    },
    {
      "epoch": 2.30505149583129,
      "grad_norm": 0.22838632762432098,
      "learning_rate": 2.695438940657185e-05,
      "loss": 0.0774,
      "step": 4700
    },
    {
      "epoch": 2.354095144678764,
      "grad_norm": 0.5344428420066833,
      "learning_rate": 2.6463952918097105e-05,
      "loss": 0.0417,
      "step": 4800
    },
    {
      "epoch": 2.4031387935262383,
      "grad_norm": 22.035152435302734,
      "learning_rate": 2.5973516429622363e-05,
      "loss": 0.0567,
      "step": 4900
    },
    {
      "epoch": 2.4521824423737124,
      "grad_norm": 0.08744075149297714,
      "learning_rate": 2.5483079941147624e-05,
      "loss": 0.0455,
      "step": 5000
    },
    {
      "epoch": 2.501226091221187,
      "grad_norm": 0.03324246034026146,
      "learning_rate": 2.4992643452672882e-05,
      "loss": 0.0401,
      "step": 5100
    },
    {
      "epoch": 2.550269740068661,
      "grad_norm": 0.06227118521928787,
      "learning_rate": 2.4502206964198136e-05,
      "loss": 0.0497,
      "step": 5200
    },
    {
      "epoch": 2.5993133889161353,
      "grad_norm": 0.04855506867170334,
      "learning_rate": 2.4011770475723394e-05,
      "loss": 0.054,
      "step": 5300
    },
    {
      "epoch": 2.64835703776361,
      "grad_norm": 4.699512004852295,
      "learning_rate": 2.3521333987248652e-05,
      "loss": 0.0651,
      "step": 5400
    },
    {
      "epoch": 2.697400686611084,
      "grad_norm": 0.18188582360744476,
      "learning_rate": 2.303089749877391e-05,
      "loss": 0.0445,
      "step": 5500
    },
    {
      "epoch": 2.746444335458558,
      "grad_norm": 0.02570282854139805,
      "learning_rate": 2.2540461010299167e-05,
      "loss": 0.0546,
      "step": 5600
    },
    {
      "epoch": 2.7954879843060323,
      "grad_norm": 0.07410647720098495,
      "learning_rate": 2.2050024521824425e-05,
      "loss": 0.0682,
      "step": 5700
    },
    {
      "epoch": 2.8445316331535064,
      "grad_norm": 0.07189459353685379,
      "learning_rate": 2.1559588033349683e-05,
      "loss": 0.0639,
      "step": 5800
    },
    {
      "epoch": 2.893575282000981,
      "grad_norm": 0.4753597676753998,
      "learning_rate": 2.106915154487494e-05,
      "loss": 0.0407,
      "step": 5900
    },
    {
      "epoch": 2.942618930848455,
      "grad_norm": 0.2782798111438751,
      "learning_rate": 2.0578715056400198e-05,
      "loss": 0.0802,
      "step": 6000
    },
    {
      "epoch": 2.9916625796959293,
      "grad_norm": 1.2578743696212769,
      "learning_rate": 2.0088278567925456e-05,
      "loss": 0.0669,
      "step": 6100
    },
    {
      "epoch": 3.0407062285434034,
      "grad_norm": 0.012234569527208805,
      "learning_rate": 1.9597842079450714e-05,
      "loss": 0.0235,
      "step": 6200
    },
    {
      "epoch": 3.089749877390878,
      "grad_norm": 0.048110149800777435,
      "learning_rate": 1.9107405590975968e-05,
      "loss": 0.0248,
      "step": 6300
    },
    {
      "epoch": 3.138793526238352,
      "grad_norm": 0.219514399766922,
      "learning_rate": 1.861696910250123e-05,
      "loss": 0.0109,
      "step": 6400
    },
    {
      "epoch": 3.1878371750858263,
      "grad_norm": 0.012653999030590057,
      "learning_rate": 1.8126532614026483e-05,
      "loss": 0.0101,
      "step": 6500
    },
    {
      "epoch": 3.2368808239333005,
      "grad_norm": 0.023605110123753548,
      "learning_rate": 1.7636096125551744e-05,
      "loss": 0.0299,
      "step": 6600
    },
    {
      "epoch": 3.285924472780775,
      "grad_norm": 0.010677535086870193,
      "learning_rate": 1.7145659637077e-05,
      "loss": 0.0146,
      "step": 6700
    },
    {
      "epoch": 3.334968121628249,
      "grad_norm": 0.21862824261188507,
      "learning_rate": 1.6655223148602256e-05,
      "loss": 0.0309,
      "step": 6800
    },
    {
      "epoch": 3.3840117704757233,
      "grad_norm": 0.02128911204636097,
      "learning_rate": 1.6164786660127514e-05,
      "loss": 0.0274,
      "step": 6900
    },
    {
      "epoch": 3.4330554193231975,
      "grad_norm": 0.051700469106435776,
      "learning_rate": 1.5674350171652772e-05,
      "loss": 0.0175,
      "step": 7000
    },
    {
      "epoch": 3.482099068170672,
      "grad_norm": 0.02383883111178875,
      "learning_rate": 1.518391368317803e-05,
      "loss": 0.0282,
      "step": 7100
    },
    {
      "epoch": 3.531142717018146,
      "grad_norm": 0.018509868532419205,
      "learning_rate": 1.4693477194703287e-05,
      "loss": 0.0256,
      "step": 7200
    },
    {
      "epoch": 3.5801863658656203,
      "grad_norm": 0.01753685437142849,
      "learning_rate": 1.4203040706228543e-05,
      "loss": 0.0178,
      "step": 7300
    },
    {
      "epoch": 3.6292300147130945,
      "grad_norm": 0.029608728364109993,
      "learning_rate": 1.3712604217753803e-05,
      "loss": 0.034,
      "step": 7400
    },
    {
      "epoch": 3.678273663560569,
      "grad_norm": 0.33165740966796875,
      "learning_rate": 1.3222167729279059e-05,
      "loss": 0.0295,
      "step": 7500
    },
    {
      "epoch": 3.727317312408043,
      "grad_norm": 0.027698399499058723,
      "learning_rate": 1.2731731240804318e-05,
      "loss": 0.0321,
      "step": 7600
    },
    {
      "epoch": 3.7763609612555173,
      "grad_norm": 0.013785867020487785,
      "learning_rate": 1.2241294752329574e-05,
      "loss": 0.0261,
      "step": 7700
    },
    {
      "epoch": 3.825404610102992,
      "grad_norm": 0.01859070174396038,
      "learning_rate": 1.1750858263854832e-05,
      "loss": 0.0273,
      "step": 7800
    },
    {
      "epoch": 3.874448258950466,
      "grad_norm": 0.06516265869140625,
      "learning_rate": 1.126042177538009e-05,
      "loss": 0.0429,
      "step": 7900
    },
    {
      "epoch": 3.92349190779794,
      "grad_norm": 0.12496238946914673,
      "learning_rate": 1.0769985286905346e-05,
      "loss": 0.017,
      "step": 8000
    },
    {
      "epoch": 3.9725355566454144,
      "grad_norm": 0.028191793709993362,
      "learning_rate": 1.0279548798430603e-05,
      "loss": 0.0318,
      "step": 8100
    },
    {
      "epoch": 4.0215792054928885,
      "grad_norm": 0.01434302981942892,
      "learning_rate": 9.789112309955861e-06,
      "loss": 0.0103,
      "step": 8200
    },
    {
      "epoch": 4.070622854340363,
      "grad_norm": 0.019102919846773148,
      "learning_rate": 9.298675821481119e-06,
      "loss": 0.0182,
      "step": 8300
    },
    {
      "epoch": 4.119666503187837,
      "grad_norm": 0.01892157457768917,
      "learning_rate": 8.808239333006377e-06,
      "loss": 0.012,
      "step": 8400
    },
    {
      "epoch": 4.168710152035311,
      "grad_norm": 0.01703605428338051,
      "learning_rate": 8.317802844531633e-06,
      "loss": 0.0083,
      "step": 8500
    }
  ],
  "logging_steps": 100,
  "max_steps": 10195,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.577047419830272e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
