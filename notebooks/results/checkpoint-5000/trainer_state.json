{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.4521824423737124,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.04904364884747425,
      "grad_norm": 11.129484176635742,
      "learning_rate": 4.9514467876410006e-05,
      "loss": 0.1417,
      "step": 100
    },
    {
      "epoch": 0.0980872976949485,
      "grad_norm": 0.05864883214235306,
      "learning_rate": 4.9024031387935264e-05,
      "loss": 0.0971,
      "step": 200
    },
    {
      "epoch": 0.14713094654242276,
      "grad_norm": 0.03857949376106262,
      "learning_rate": 4.853359489946052e-05,
      "loss": 0.0801,
      "step": 300
    },
    {
      "epoch": 0.196174595389897,
      "grad_norm": 0.017243042588233948,
      "learning_rate": 4.804315841098578e-05,
      "loss": 0.1,
      "step": 400
    },
    {
      "epoch": 0.24521824423737126,
      "grad_norm": 0.12854889035224915,
      "learning_rate": 4.755272192251104e-05,
      "loss": 0.0972,
      "step": 500
    },
    {
      "epoch": 0.2942618930848455,
      "grad_norm": 0.5904366374015808,
      "learning_rate": 4.7062285434036295e-05,
      "loss": 0.2458,
      "step": 600
    },
    {
      "epoch": 0.34330554193231977,
      "grad_norm": 2.2150566577911377,
      "learning_rate": 4.657184894556155e-05,
      "loss": 0.2226,
      "step": 700
    },
    {
      "epoch": 0.392349190779794,
      "grad_norm": 4.080173492431641,
      "learning_rate": 4.608141245708681e-05,
      "loss": 0.2124,
      "step": 800
    },
    {
      "epoch": 0.4413928396272683,
      "grad_norm": 2.6016056537628174,
      "learning_rate": 4.559097596861207e-05,
      "loss": 0.2098,
      "step": 900
    },
    {
      "epoch": 0.4904364884747425,
      "grad_norm": 3.0120298862457275,
      "learning_rate": 4.5100539480137326e-05,
      "loss": 0.23,
      "step": 1000
    },
    {
      "epoch": 0.5394801373222168,
      "grad_norm": 8.036979675292969,
      "learning_rate": 4.4610102991662583e-05,
      "loss": 0.2088,
      "step": 1100
    },
    {
      "epoch": 0.588523786169691,
      "grad_norm": 7.919243335723877,
      "learning_rate": 4.411966650318784e-05,
      "loss": 0.2009,
      "step": 1200
    },
    {
      "epoch": 0.6375674350171653,
      "grad_norm": 4.389970302581787,
      "learning_rate": 4.36292300147131e-05,
      "loss": 0.1827,
      "step": 1300
    },
    {
      "epoch": 0.6866110838646395,
      "grad_norm": 5.468738555908203,
      "learning_rate": 4.313879352623835e-05,
      "loss": 0.2143,
      "step": 1400
    },
    {
      "epoch": 0.7356547327121138,
      "grad_norm": 5.206825256347656,
      "learning_rate": 4.2648357037763614e-05,
      "loss": 0.214,
      "step": 1500
    },
    {
      "epoch": 0.784698381559588,
      "grad_norm": 1.1600117683410645,
      "learning_rate": 4.215792054928887e-05,
      "loss": 0.2159,
      "step": 1600
    },
    {
      "epoch": 0.8337420304070623,
      "grad_norm": 1.6035795211791992,
      "learning_rate": 4.166748406081413e-05,
      "loss": 0.2043,
      "step": 1700
    },
    {
      "epoch": 0.8827856792545365,
      "grad_norm": 6.164929389953613,
      "learning_rate": 4.117704757233938e-05,
      "loss": 0.2055,
      "step": 1800
    },
    {
      "epoch": 0.9318293281020108,
      "grad_norm": 8.087772369384766,
      "learning_rate": 4.068661108386464e-05,
      "loss": 0.1858,
      "step": 1900
    },
    {
      "epoch": 0.980872976949485,
      "grad_norm": 1.5454144477844238,
      "learning_rate": 4.01961745953899e-05,
      "loss": 0.1859,
      "step": 2000
    },
    {
      "epoch": 1.0299166257969592,
      "grad_norm": 1.666582703590393,
      "learning_rate": 3.970573810691516e-05,
      "loss": 0.1327,
      "step": 2100
    },
    {
      "epoch": 1.0789602746444336,
      "grad_norm": 12.013948440551758,
      "learning_rate": 3.921530161844041e-05,
      "loss": 0.107,
      "step": 2200
    },
    {
      "epoch": 1.128003923491908,
      "grad_norm": 0.38277551531791687,
      "learning_rate": 3.872486512996567e-05,
      "loss": 0.119,
      "step": 2300
    },
    {
      "epoch": 1.177047572339382,
      "grad_norm": 0.8005583882331848,
      "learning_rate": 3.823442864149093e-05,
      "loss": 0.1106,
      "step": 2400
    },
    {
      "epoch": 1.2260912211868562,
      "grad_norm": 0.04874178394675255,
      "learning_rate": 3.774399215301619e-05,
      "loss": 0.1059,
      "step": 2500
    },
    {
      "epoch": 1.2751348700343306,
      "grad_norm": 3.550358772277832,
      "learning_rate": 3.725355566454144e-05,
      "loss": 0.1446,
      "step": 2600
    },
    {
      "epoch": 1.324178518881805,
      "grad_norm": 7.042727470397949,
      "learning_rate": 3.67631191760667e-05,
      "loss": 0.1197,
      "step": 2700
    },
    {
      "epoch": 1.373222167729279,
      "grad_norm": 1.7681925296783447,
      "learning_rate": 3.627268268759196e-05,
      "loss": 0.1254,
      "step": 2800
    },
    {
      "epoch": 1.4222658165767532,
      "grad_norm": 15.625740051269531,
      "learning_rate": 3.5782246199117216e-05,
      "loss": 0.1304,
      "step": 2900
    },
    {
      "epoch": 1.4713094654242276,
      "grad_norm": 0.682011067867279,
      "learning_rate": 3.529180971064247e-05,
      "loss": 0.1152,
      "step": 3000
    },
    {
      "epoch": 1.520353114271702,
      "grad_norm": 0.8218663334846497,
      "learning_rate": 3.480137322216773e-05,
      "loss": 0.123,
      "step": 3100
    },
    {
      "epoch": 1.569396763119176,
      "grad_norm": 20.564716339111328,
      "learning_rate": 3.431093673369299e-05,
      "loss": 0.1279,
      "step": 3200
    },
    {
      "epoch": 1.6184404119666502,
      "grad_norm": 1.2603421211242676,
      "learning_rate": 3.3820500245218246e-05,
      "loss": 0.0992,
      "step": 3300
    },
    {
      "epoch": 1.6674840608141246,
      "grad_norm": 2.3616936206817627,
      "learning_rate": 3.3330063756743504e-05,
      "loss": 0.1098,
      "step": 3400
    },
    {
      "epoch": 1.716527709661599,
      "grad_norm": 0.171383798122406,
      "learning_rate": 3.283962726826876e-05,
      "loss": 0.1333,
      "step": 3500
    },
    {
      "epoch": 1.765571358509073,
      "grad_norm": 0.1327095478773117,
      "learning_rate": 3.234919077979402e-05,
      "loss": 0.1209,
      "step": 3600
    },
    {
      "epoch": 1.8146150073565472,
      "grad_norm": 1.1744441986083984,
      "learning_rate": 3.185875429131928e-05,
      "loss": 0.1126,
      "step": 3700
    },
    {
      "epoch": 1.8636586562040216,
      "grad_norm": 15.105277061462402,
      "learning_rate": 3.1368317802844535e-05,
      "loss": 0.1319,
      "step": 3800
    },
    {
      "epoch": 1.912702305051496,
      "grad_norm": 7.916051387786865,
      "learning_rate": 3.0877881314369786e-05,
      "loss": 0.1296,
      "step": 3900
    },
    {
      "epoch": 1.96174595389897,
      "grad_norm": 0.3864770829677582,
      "learning_rate": 3.038744482589505e-05,
      "loss": 0.1327,
      "step": 4000
    },
    {
      "epoch": 2.0107896027464442,
      "grad_norm": 27.881778717041016,
      "learning_rate": 2.9897008337420308e-05,
      "loss": 0.0878,
      "step": 4100
    },
    {
      "epoch": 2.0598332515939184,
      "grad_norm": 0.6641351580619812,
      "learning_rate": 2.9406571848945563e-05,
      "loss": 0.0604,
      "step": 4200
    },
    {
      "epoch": 2.108876900441393,
      "grad_norm": 0.08584930002689362,
      "learning_rate": 2.891613536047082e-05,
      "loss": 0.0637,
      "step": 4300
    },
    {
      "epoch": 2.157920549288867,
      "grad_norm": 17.782451629638672,
      "learning_rate": 2.8425698871996075e-05,
      "loss": 0.0453,
      "step": 4400
    },
    {
      "epoch": 2.2069641981363413,
      "grad_norm": 0.03465844690799713,
      "learning_rate": 2.793526238352134e-05,
      "loss": 0.0639,
      "step": 4500
    },
    {
      "epoch": 2.256007846983816,
      "grad_norm": 0.05975571274757385,
      "learning_rate": 2.7444825895046593e-05,
      "loss": 0.0631,
      "step": 4600
    },
    {
      "epoch": 2.30505149583129,
      "grad_norm": 0.22838632762432098,
      "learning_rate": 2.695438940657185e-05,
      "loss": 0.0774,
      "step": 4700
    },
    {
      "epoch": 2.354095144678764,
      "grad_norm": 0.5344428420066833,
      "learning_rate": 2.6463952918097105e-05,
      "loss": 0.0417,
      "step": 4800
    },
    {
      "epoch": 2.4031387935262383,
      "grad_norm": 22.035152435302734,
      "learning_rate": 2.5973516429622363e-05,
      "loss": 0.0567,
      "step": 4900
    },
    {
      "epoch": 2.4521824423737124,
      "grad_norm": 0.08744075149297714,
      "learning_rate": 2.5483079941147624e-05,
      "loss": 0.0455,
      "step": 5000
    }
  ],
  "logging_steps": 100,
  "max_steps": 10195,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.104256976347136e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
